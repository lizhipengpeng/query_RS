
### TODO

1. 训练、验证、测试数据集划分


2. 找baseline模型


3. 跑自己的模型 和 baseline模型 


### 不足


1. label标签设置有点问题

   绝大多数label是(0,0,0,0) 导致反向传播效果很差

2. gpt按理说应该在整个query pool中训练，只在很小的数据集中训练效果有可能不好

3. GPT到底用不用预训练的模型，如果不用就得用自己的文本训练效果会好，但是成本高，如果用，很容易受之前预训练的影响    **T5**

4. 使用user_id embedding 而不是那些特征 词典的问题 就得提前把词典弄好

5. BERT使用<CLS>的pre，可以换成使用整个句子的平均pre

6. 确定评价指标

7. 美团电脑VPN问题，一锁屏就断开



### 实验设计

#### 1. 数据处理

**所用数据**

> - 用户特征数据：用户ID
> - input
> - query 文本（可用POI 名称作为文本数据）

- 训练数据：50万用户的一月的数据量
- 验证数据：50万用户的一天的数据量
- 测试数据：50万用户的一天的数据量

---

#### 2. 预训练

1. BERT 预训练

   > 代码：用d2l中的代码？？
   >
   > 数据

2. GPT 预训练

   > 代码：可以用`提示学习用于可解释推荐系统`这篇文章的代码
   >
   > 数据

3. model_1的训练 —— > GPT微调

   > 代码
   >
   > 数据

4. 整个模型的训练

---

#### 3. 训练

---

#### 4. 预测

---

### 实验结果
